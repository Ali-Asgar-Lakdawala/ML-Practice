{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "spam detection Naive Bayes Classifier .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ali-Asgar-Lakdawala/ML-Practice/blob/main/spam_detection_Naive_Bayes_Classifier_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYsTFWXYjCxF"
      },
      "source": [
        "# <u><b> Objective </b></u>\n",
        "## <b> Your task is to predict whether a message will be spam or not. In the class we used the <code>sklearn.countvectorizer</code> to find vectors for each message. Now you need to do the same task but rather than using countvectorizer, you are required to use TF-IDF vectorizer to find the vectors for the messages. </b>\n",
        "\n",
        "### You will use <code>tfidfVectorizer</code>. It will convert collection of text documents (SMS corpus) into 2D matrix. One dimension represent documents and other dimension repesents each unique word in SMS corpus.\n",
        "\n",
        "### If $n^{th}$ term $t$ has occured $p$ times in $m^{th}$ document, $(m, n)$ value in this matrix will be $\\rm TF-IDF(t)$, where \n",
        "$\\rm TF-IDF(t) = \\rm Term ~Frequency (TF) * \\rm Inverse~ Document ~Frequency (IDF)$\n",
        "* ### <b>Term Frequency (TF)</b> is a measure of how frequent a term occurs in a document.\n",
        "\n",
        "* ### $TF(t)$= Number of times term $t$ appears in document ($p$) / Total number of terms in that document\n",
        "\n",
        "* ### <b>Inverse Document Frequency (IDF)</b> is measure of how important term is. For TF, all terms are equally treated. But, in IDF, for words that occur frequently like 'is' 'the' 'of' are assigned less weight. While terms that occur rarely that can easily help identify class of input features will be weighted high.\n",
        "\n",
        "* ###  $IDF(t)= log(\\frac{\\rm Total ~ number ~ of ~document}{ Number ~of~ documents~ with ~term ~t ~in~ it})$\n",
        "\n",
        "### At end we will have for every message, vectors normalized to unit length equal to size of vocabulary (number of unique terms from entire SMS corpus)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sWnaTKVANty",
        "outputId": "4b88c927-c159-453e-fc04-0c3c151adb6d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vidAEMgLAiLe"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkiR0K5XAWy-"
      },
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ML/spam.csv\", encoding='latin-1')[['v1', 'v2']]"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEk7tvOLAgrD"
      },
      "source": [
        "df.v2=df.v2.apply(lambda x:x.lower())"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "GIWHiatbG8un",
        "outputId": "f29b9e0f-ee93-48bb-8653-69dc5e13d02c"
      },
      "source": [
        "df"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>will ì_ b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>pity, * was in mood for that. so...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>the guy did some bitching but i acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>rofl. its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        v1                                                 v2\n",
              "0      ham  go until jurong point, crazy.. available only ...\n",
              "1      ham                      ok lar... joking wif u oni...\n",
              "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
              "3      ham  u dun say so early hor... u c already then say...\n",
              "4      ham  nah i don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  this is the 2nd time we have tried 2 contact u...\n",
              "5568   ham              will ì_ b going to esplanade fr home?\n",
              "5569   ham  pity, * was in mood for that. so...any other s...\n",
              "5570   ham  the guy did some bitching but i acted like i'd...\n",
              "5571   ham                         rofl. its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2POn06FG0oB"
      },
      "source": [
        "import string"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF1-IvvmBCEO"
      },
      "source": [
        "df.v2=df.v2.apply(lambda x:x.translate(str.maketrans('', '', string.punctuation))) "
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "M7415xq8HQhT",
        "outputId": "8f82b8c6-e12c-4f45-bf55-80e955ee8d7f"
      },
      "source": [
        "df"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>will ì b going to esplanade fr home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>pity  was in mood for that soany other suggest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>the guy did some bitching but i acted like id ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>rofl its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        v1                                                 v2\n",
              "0      ham  go until jurong point crazy available only in ...\n",
              "1      ham                            ok lar joking wif u oni\n",
              "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
              "3      ham        u dun say so early hor u c already then say\n",
              "4      ham  nah i dont think he goes to usf he lives aroun...\n",
              "...    ...                                                ...\n",
              "5567  spam  this is the 2nd time we have tried 2 contact u...\n",
              "5568   ham                will ì b going to esplanade fr home\n",
              "5569   ham  pity  was in mood for that soany other suggest...\n",
              "5570   ham  the guy did some bitching but i acted like id ...\n",
              "5571   ham                          rofl its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-FboDrtHTp4",
        "outputId": "21cab124-4864-4f7c-e1ad-e53e73e3f2f9"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e04Eh_pZLeye"
      },
      "source": [
        "stop = stopwords.words('english')"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6n2MM6DK0m_"
      },
      "source": [
        "df.v2=df.v2.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgDLu2H-OLor"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hdMg_jQOP8m"
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_df=0.95,norm='l1')\n",
        "X = vectorizer.fit_transform(df.v2)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "v-VJ-l7aPTUV",
        "outputId": "9f345428-583e-4f27-86bf-7b7138bc1d76"
      },
      "source": [
        "df.iloc[4065].v2"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fyi im gonna call sporadically starting like ltgt bc doin shit'"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-njwRWq4PBHO",
        "outputId": "8a26d61e-cf00-491a-f9d8-3c43d8054329"
      },
      "source": [
        "sum(X.toarray()[4065])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm-ET2zrPpJN"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "msg_train,msg_test,label_train,label_test = train_test_split(df.v2,df.v1,test_size=0.2)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EptnJgdGMUS"
      },
      "source": [
        "train_vectorized = vectorizer.transform(msg_train)\n",
        "test_vectorized = vectorizer.transform(msg_test)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltHiuyb2Gdxg"
      },
      "source": [
        "train_array= train_vectorized.toarray()\n",
        "test_array = test_vectorized.toarray()"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "9ae436fe7af2fca2dc7b0fd25d44567c88aa24b8",
        "id": "HLrQuWVyxLYf"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "spam_detect_model = GaussianNB().fit(train_array,label_train)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koOOJdf0FTks"
      },
      "source": [
        "train_preds = spam_detect_model.predict(train_array)\n",
        "test_preds = spam_detect_model.predict(test_array)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "03ac047e8e9e996e7723e901bf00fd7478ab9755",
        "id": "SCJo7wD7xLYg"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb0ocgK0G8Vk",
        "outputId": "dbcefd65-2dc8-4db8-e85b-bcf99efaaa63"
      },
      "source": [
        "# Confusion matrices for train and test \n",
        "print(confusion_matrix(label_test,test_preds))"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[854  94]\n",
            " [ 26 141]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZFPjPmboB_5",
        "outputId": "0fc8aed8-f579-4658-83ca-8d1d7b84bf51"
      },
      "source": [
        "# Print the classification report for train and test\n",
        "print(classification_report(label_test,test_preds))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      0.90      0.93       948\n",
            "        spam       0.60      0.84      0.70       167\n",
            "\n",
            "    accuracy                           0.89      1115\n",
            "   macro avg       0.79      0.87      0.82      1115\n",
            "weighted avg       0.91      0.89      0.90      1115\n",
            "\n"
          ]
        }
      ]
    }
  ]
}